class(agricultureLogical)
install.packages("jpeg")
library(jpeg)
require(downloader)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download(fileUrl,"jeff.jpg",mode = "wb")
img.n<-readJPEG("jeff.jpg",TRUE)
quantile(img.n,probs=c(0.3,0.8))
require(downloader)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download(fileUrl,"gdp.csv",mode = "wb")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download(fileUrl,"edu.csv",mode = "wb")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download(fileUrl,"edu.csv",mode = "wb")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
require(downloader)
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
download.file(file.url, file.dest )
fed <- read.csv('GDP2.csv')
View(fed)
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
combined[with(combined, order(-V2) )]
combined[with(combined, order(-V2))]
combined[with(combined, order(-V2) )]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip=4, nrows=215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "gdp"))
install.packages(data.table)
library("data.table", lib.loc="~/R/win-library/3.2")
install.packages("data.table")
library("data.table")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
f <- file.path(getwd(), "EDSTATS_Country.csv")
download.file(url, f)
dtEd <- data.table(read.csv(f))
dt <- merge(dtGDP, dtEd, all=TRUE, by=c("CountryCode"))
sum(!is.na(unique(dt$rankingGDP)))
dt[order(rankingGDP, decreasing=TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, gdp)][13]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip=4, nrows=215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "gdp"))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
f <- file.path(getwd(), "EDSTATS_Country.csv")
download.file(url, f)
dtEd <- data.table(read.csv(f))
dt <- merge(dtGDP, dtEd, all=TRUE, by=c("CountryCode"))
sum(!is.na(unique(dt$rankingGDP)))
dt[order(rankingGDP, decreasing=TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, gdp)][13]
dt[, mean(rankingGDP, na.rm=TRUE), by=Income.Group]
breaks <- quantile(dt$rankingGDP, probs=seq(0, 1, 0.2), na.rm=TRUE)
dt$quantileGDP <- cut(dt$rankingGDP, breaks=breaks)
dt[Income.Group == "Lower middle income", .N, by=c("Income.Group", "quantileGDP")]
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
download.file(file.url, file.dest )
rowNames <- seq(10,200, 2)
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
download.file(file.url, file.dest )
fed <- read.csv('GDP2.csv')
View(fed)
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
combined[with(combined, order(-V2) )]
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
view(q1)
View(q1)
View(q)
xtabs(q1 ~ combined$Income.Group)
version
install.packages("Exploratory Data Analysis")
library(swirl)
swirl()
head(PM2.5)
head(pollution)
dim(pollution)
summary(pollution$pm25)
quantile(ppm)
summary(pollution$pm25)
boxplot(ppm,col="blue")
abline(h = 12)
hist(ppm, col = "green")
rug(ppm)
hist(ppm, col = "green", breaks = 100)
low
high
hist(ppm, col = "green", breaks = 100)
rug(ppm)
hist(ppm, col = 'green')
abline (v=12, lwd = 2)
abline(v = median(ppm), col = "magenta", lwd = 4)
names(pollution)
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main = "Number of Counties in Each Region")
boxplot(pm25 ~ region, data = pollution, col = "red")
par(mfrow=c(2,1),mar=c(4,4,2,1))
east <- subset(pollution,region=="east")
head (east)
hist(east$pm25, col = "green")
hist(subset(pollution,region=="west")$pm25, col = "green")
with(pollution, plot(latitude, pm25))
abline(h = 12, lwd = 2, lty = 2)
plot(pollution$latitude, ppm, col = pollution$region)
abline(h = 12, lwd = 2, lty = 2)
par(mfrow = c(1, 2),mar = c(5, 4, 2, 1))
west <- subset(pollution,region=="west")
plot(west$latitude, west$pm25, main = "West")
plot(east$latitude, east$pm25, main = "East")
bye()
library(swirl)
swirl()
test
quit()
library(swirld)
library(swirl)
swirl()
head(PM2.5)
head(pollution)
dim(pollution)
summary(pollution$pm25)
ppm <- summary(pollution$pm25)
quantile(ppm)
boxplot(ppm)
boxplot(ppm,col='blue')
abline(ppm,h='12')
abline(ppm,h=12)
abline(h=12)
hist(ppm)
hist(ppm,col='green')
rug(ppm)
hist(ppm, col = "green", breaks = 100)
low
high
hist(ppm, col = "green", breaks = 100)
rug(ppm)
hist(ppm, col = "green")
abline(v = 12, lwd=2)
abline(v = median(ppm), col = "magenta", lwd = 4)
names(pollution)
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main = "Number of Counties in Each Region")
boxplot(pm25 ~ region, data = pollution, col = "red")
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
east <- subset(pollution,region=="east")
head(east)
hist(east$pm25, col = "green")
hist(subset(pollution,region=="west")$pm25, col = "green")
with(pollution, plot(latitude, pm25))
abline(h = 12, lwd = 2, lty = 2)
plot(pollution$latitude, ppm, col = pollution$region)
plot(pollution$latitude, ppm, col = pollution$region)
plot(pollution$latitude, ppm, col = pollution$region)
plot(pollution$latitude, ppm, col = 'pollution$region')
plot(pollution$latitude, ppm, col = pollution$region)
plot(pollution$latitude, ppm, col = pollution$region)
plot()
plot(pollution$latitude, ppm, col = pollution$region)
plot(pollution$latitude, ppm, col = pollution$region)
plot(pollution$latitude, ppm, col = pollution$region)
plot(pollution$latitude, ppm, col = pollution$region)
q()
data(sleep)
head(sleep)
swirl()
swirl
library(swirl)
swirl()
0.64
64%
.64
mypdf
integrate(mypdf,0,0.16)
integrate(mypdf,0,1.16)
integrate(mypdf,0,1.6)
1.414214
.997*.001
(1-.985)*(1-.001)
.000997/(.000997+.014985)
head(ToothGrowth, 5)
head(ToothGrowth)
ggplot( tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels")
ggplot2( tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels")
library(ggplot2)
ggplot(tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels")
library(datasets)
data(ToothGrowth)
tooth <- ToothGrowth
ggplot(tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels")
ggplot (height=600, width=800) + (tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels"))
ggplot (height=600, width=800) + (tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels")
ggplot (tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels")
opts(plot.margin = unit(c(2, 2, 2, 2), "cm"))
ggplot (tooth, aes(x = dose, y = len, color = supp)) +
geom_point(shape = 4) +
geom_smooth(method=lm) +
ylab("Tooth Length") +
xlab("Vitamin C Dose in milligrams") +
ggtitle("Tooth Length vs Vitamin C Dose Levels")
library(swirl)
swirl()
1/2
1/6
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
3.5
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam,1,mean)
mean(smeans)
dice_sqr
ex2_fair <- sum(dice_fair * dice_sqr)
ex2_fair-3.5^2
sum(dice_high * dice_sqr)-edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
text <- readLines(filePath)
filepath <- "D:/TM/TM@NIA-BigData/StudyData/VoC/corpus.txt"
text <- readLines(filePath)
filePath <- "D:/TM/TM@NIA-BigData/StudyData/VoC/corpus.txt"
text <- readLines(filePath)
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(30000)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=20000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
set.seed(2000)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
filePath <- "D:/TM/TM@NIA-BigData/StudyData/VoC/corpus.txt"
text <- readLines(filePath)
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(2000)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
set.seed(1000)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
swirl()
library(swirl)
swirl()
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
quit()
library(swirl)
swirl()
fit <- lm(child ~ parent, galton)
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$parent,galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ . - 1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ . - 1, trees2)
lapply(list(fit, fit2), coef)
myts <- ts(myvector, start=c(2009, 1), end=c(2014, 12), frequency=12)
AirPassengers
f <- decompose(AirPassengers)
f
f <- decompose(AirPassengers)
plot(f$figure, type=”b”, xaxt=”n”, xlab=”")
plot(f$figure, type='b', xaxt='n', xlab='')
monthNames <- months(ISOdate(2011,1:12,1))
axis(1, at=1:12, labels=monthNames, las=2)
plot(f)
fit <- arima(AirPassengers, order=c(1,0,0), list(order=c(2,1,0), period=12))
fore <- predict(fit, n.ahead=24)
U <- fore$pred + 2*fore$se
L <- fore$pred – 2*fore$se
L <- fore$pred – 2*fore$se
U <- fore$pred + 2*fore$se
zte <- c(0.238532642, 0.2467982, 0.351683715, 0.358178113, 0.428171563, 0.456365228, 0.441400304, 0.483568472, 0.490649869, 0.506307822)
zte
zte_decom <- decompose(zte)
plot(zte_decom$figure, type='b', xaxt='n', xlab='')
zte_decom <- decompose(zte)
install.packages(caret)
install.packages("caret")
library(caret)
require(caret)
install.packages("pbkrtest")
require(caret)
require(pbkrtest)
install.packages("kernlab")
require(caret)
install.packages("caret")
require(caret)
require(pbkrtest)
install.packages("pbkrtest")
require(pbkrtest)
require(caret)
data("iris")
data(iris)
library(ggplot2)
name(iris)
names(iris)
table(iris$Species)
ctrlKNN = trainControl(method = "adaptive_cv")
setwd("C:/Users/MohdRizal/Dropbox/DataScience/machine-learning/project")
library(AppliedPredictiveModeling)
library(caret)
library(rattle)
library(rpart.plot)
library(randomForest)
ctrlKNN = trainControl(method = "adaptive_cv")
modelKNN = train(classe ~ ., training, method = "knn", trControl = ctrlKNN)
rm(list = ls())
if (!file.exists("machine-learning-training.csv")) {
download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "machine-learning-training.csv")
}
if (!file.exists("machine-learning-testing.csv")) {
download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "machine-learning-testing.csv")
}
testing <- read.csv("machine-learning-testing.csv", sep = ",", na.strings = c("", "NA"))
training <- read.csv("machine-learning-training.csv", sep = ",", na.strings = c("", "NA"))
features <- names(testing[,colSums(is.na(testing)) == 0])[8:59]
training <- training[,c(features,"classe")]
testing <- testing[,c(features,"problem_id")]
dim(training)
dim(testing)
nzv <- nearZeroVar(training, saveMetrics=TRUE)
nzv
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
outcome = which(names(myTraining) == "classe")
highCorrCols = findCorrelation(abs(cor(myTraining[,-outcome])),0.90)
highCorrFeatures = names(myTraining)[highCorrCols]
myTraining = myTraining[,-highCorrCols]
outcome = which(names(myTraining) == "classe")
highCorrFeatures
fsRF = randomForest(myTraining[,-outcome], myTraining[,outcome], importance = T)
rfImp = data.frame(fsRF$importance)
impFeatures = order(-rfImp$MeanDecreaseGini)
inImp = createDataPartition(myTraining$classe, p = 0.05, list = F)
featurePlot(myTraining[inImp,impFeatures[1:4]],myTraining$classe[inImp], plot = "pairs")
ctrlKNN = trainControl(method = "adaptive_cv")
modelKNN = train(classe ~ ., training, method = "knn", trControl = ctrlKNN)
fancyRpartPlot(modelKNN)
ctrlRF = trainControl(method = "oob")
modelRF = train(classe ~ ., myTraining, method = "rf", ntree = 200, trControl = ctrlRF)
resultsKNN = data.frame(modelKNN$results)
resultsRF = data.frame(modelRF$results)
modelRF
fitKNN = predict(modelKNN, testing)
fitRF = predict(modelRF, testing)
predictions <- predict(modelRF, newdata=myTesting)
predictions
print(confusionMatrix(predictions, myTesting$classe), digits=4)
